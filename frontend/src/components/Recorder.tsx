import { useState, useRef } from "react";
import { analyzeVoice } from "../api";

type Props = {
  onResult: (data: any) => void;
};

export default function Recorder({ onResult }: Props) {
  const [recording, setRecording] = useState(false);
  const [loading, setLoading] = useState(false);
  const mediaRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<Blob[]>([]);

  const start = async () => {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const recorder = new MediaRecorder(stream);
    chunksRef.current = [];

    recorder.ondataavailable = (e) => {
      if (e.data.size > 0) chunksRef.current.push(e.data);
    };

    recorder.onstop = async () => {
      stream.getTracks().forEach((t) => t.stop());
      const blob = new Blob(chunksRef.current, { type: "audio/webm" });
      setLoading(true);
      try {
        const result = await analyzeVoice(blob);
        onResult(result);
      } catch (err) {
        console.error(err);
        onResult({ error: "è§£æã«å¤±æ•—ã—ã¾ã—ãŸ" });
      } finally {
        setLoading(false);
      }
    };

    recorder.start();
    mediaRef.current = recorder;
    setRecording(true);
  };

  const stop = () => {
    mediaRef.current?.stop();
    setRecording(false);
  };

  return (
    <div style={{ textAlign: "center", padding: "2rem" }}>
      {loading ? (
        <p>ğŸ”„ è§£æä¸­...</p>
      ) : (
        <button
          onClick={recording ? stop : start}
          style={{
            fontSize: "1.5rem",
            padding: "1rem 3rem",
            borderRadius: "50px",
            border: "none",
            color: "#fff",
            background: recording ? "#e74c3c" : "#3498db",
            cursor: "pointer",
          }}
        >
          {recording ? "â¹ éŒ²éŸ³åœæ­¢" : "ğŸ¤ éŒ²éŸ³é–‹å§‹"}
        </button>
      )}
      {recording && (
        <p style={{ marginTop: "1rem", color: "#e74c3c" }}>
          ğŸ”´ éŒ²éŸ³ä¸­... ä½ã„å£°ã‹ã‚‰é«˜ã„å£°ã¾ã§å‡ºã—ã¦ãã ã•ã„
        </p>
      )}
    </div>
  );
}