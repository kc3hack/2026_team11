import numpy as np
import soundfile as sf
import torch
import torchcrepe
import librosa
from register_classifier import classify_register, reset_register_stats, print_register_summary
from note_converter import hz_to_label_and_hz
from config import (
    VOICE_MIN_HZ, VOICE_MAX_HZ, CREPE_SR, CREPE_HOP_LENGTH,
    FALSETTO_DISPLAY_MIN_HZ, CONF_THRESHOLDS, CONF_MIN_FRAMES,
    CHEST_OUTLIER_PERCENTILE, CHEST_OUTLIER_GAP_ST,
    FALSETTO_OUTLIER_PERCENTILE, FALSETTO_OUTLIER_GAP_ST,
    NO_FALSETTO_OUTLIER_PERCENTILE, NO_FALSETTO_OUTLIER_GAP_ST,
    CLEANUP_SEMITONES,
    GRADUATED_CONF_FAR, GRADUATED_CONF_MID, GRADUATED_CONF_NEAR,
    UNREALISTIC_LOWER_OCT, UNREALISTIC_UPPER_OCT,
    MIN_SUSTAIN_FRAMES,
)


# ============================================================
# fix_octave_errors
# ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ¼åˆ¤å®šãƒ»ä¸­å¤®å€¤è¨ˆç®—ç”¨ã®ã‚ªã‚¯ã‚¿ãƒ¼ãƒ–ä¿®æ­£
# â˜… min/maxã«ã¯ä½¿ã‚ãªã„ï¼ˆä¸­å¤®å€¤ã«å¼•ãå¯„ã›ã¦æ­£ã—ã„æœ€é«˜éŸ³ã‚’å‰Šã£ã¦ã—ã¾ã†ãŸã‚ï¼‰
# ============================================================
def fix_octave_errors(f0: np.ndarray, conf: np.ndarray) -> np.ndarray:
    if len(f0) < 5:
        return f0.copy()
    f0_fixed  = f0.copy()
    hc        = conf >= 0.5
    reference = np.median(f0[hc]) if hc.sum() >= 5 else np.median(f0)

    for i, freq in enumerate(f0_fixed):
        if freq <= 0:
            continue
        # é«˜éŸ³ä¿è­·: ä¸­å¤®å€¤ã®1.5å€ä»¥ä¸Šã‹ã¤äººå£°ç¯„å›²å†…ã‹ã¤é«˜ä¿¡é ¼åº¦ â†’ æ­£å½“ãªé«˜éŸ³è·³èºãªã®ã§è£œæ­£ã—ãªã„
        # ãƒã‚¤ã‚ºãƒ•ãƒ¬ãƒ¼ãƒ (conf<0.5)ã¯ä¿è­·ã›ãšã‚ªã‚¯ã‚¿ãƒ¼ãƒ–è£œæ­£ã®å¯¾è±¡ã«æ®‹ã™
        if freq > reference * 1.5 and VOICE_MIN_HZ <= freq <= VOICE_MAX_HZ and conf[i] >= 0.5:
            continue
        doubled, halved = freq * 2, freq / 2
        can_up   = VOICE_MIN_HZ <= doubled <= VOICE_MAX_HZ
        can_down = VOICE_MIN_HZ <= halved  <= VOICE_MAX_HZ
        d_orig   = abs(freq    - reference)
        d_up     = abs(doubled - reference) if can_up   else float('inf')
        d_down   = abs(halved  - reference) if can_down else float('inf')
        if can_up   and d_up   < d_orig and d_up   < d_down: f0_fixed[i] = doubled
        elif can_down and d_down < d_orig and d_down < d_up:  f0_fixed[i] = halved
    return f0_fixed


# ============================================================
# remove_unrealistic_range
# éå¯¾ç§°ãƒ•ã‚£ãƒ«ã‚¿: ä¸‹é™ã¯å³æ ¼ï¼ˆã‚µãƒ–ãƒãƒ¼ãƒ¢ãƒ‹ã‚¯ã‚¹é™¤å»ï¼‰ã€ä¸Šé™ã¯ç·©å’Œï¼ˆé«˜éŸ³ä¿æŒï¼‰
# ============================================================
def remove_unrealistic_range(f0: np.ndarray, conf: np.ndarray) -> tuple:
    if len(f0) < 5:
        return f0.copy(), conf.copy()
    hc     = conf >= 0.3
    median = np.median(f0[hc]) if hc.sum() >= 3 else np.median(f0)
    lower_factor = 2 ** UNREALISTIC_LOWER_OCT
    upper_factor = 2 ** UNREALISTIC_UPPER_OCT
    mask = (f0 >= median / lower_factor) & (f0 <= median * upper_factor)
    return f0[mask], conf[mask]


# ============================================================
# remove_isolated_extremes
# å­¤ç«‹ã—ãŸæ¥µç«¯ãªé«˜éŸ³ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é™¤å»ï¼ˆãƒã‚¤ã‚ºå¯¾ç­–ã®æœ€çµ‚é˜²è¡›ç·šï¼‰
# ============================================================
def remove_isolated_extremes(notes, min_neighbors=4):
    """å­¤ç«‹ã—ãŸæ¥µç«¯å€¤ã‚’é™¤å»ã€‚1åŠéŸ³ä»¥å†…ã«min_neighborsæœªæº€ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¯é™¤å¤–"""
    if len(notes) < min_neighbors:
        return notes
    arr = np.array(notes)
    median_val = np.median(arr)
    # ä¸­å¤®å€¤ã®1.5å€ä»¥ä¸Šã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ãƒã‚§ãƒƒã‚¯ï¼ˆä½éŸ³å´ã¯å¯¾è±¡å¤–ï¼‰
    high_threshold = median_val * 1.5
    semitone = 2 ** (1 / 12)  # â‰ˆ1.0595
    result = []
    removed = 0
    for f in notes:
        if f < high_threshold:
            result.append(f)
            continue
        # 1åŠéŸ³ä»¥å†…ã®è¿‘å‚ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        neighbors = sum(1 for x in notes if f / semitone <= x <= f * semitone)
        if neighbors >= min_neighbors:
            result.append(f)
        else:
            removed += 1
    if removed > 0:
        print(f"[DEBUG] å­¤ç«‹ãƒ•ãƒ¬ãƒ¼ãƒ é™¤å»: {removed}ãƒ•ãƒ¬ãƒ¼ãƒ å‰Šé™¤ (é–¾å€¤={high_threshold:.1f}Hzä»¥ä¸Š, è¿‘å‚{min_neighbors}æœªæº€)")
    return result if result else notes  # å…¨é™¤å»ã‚’é˜²æ­¢


# ============================================================
# remove_statistical_outliers
# ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®å¤–ã‚Œå€¤é™¤å»ï¼ˆãƒã‚¤ã‚ºãƒ»ä¼´å¥æ··å…¥ã®å®‰å…¨ãƒãƒƒãƒˆï¼‰
# ============================================================
def remove_statistical_outliers(notes, percentile=97, max_semitones_gap=6):
    """ä¸»è¦åˆ†å¸ƒã‹ã‚‰å¤§ããé›¢ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é™¤å»ã€‚
    P{percentile}ã‹ã‚‰{max_semitones_gap}åŠéŸ³ä»¥ä¸Šé›¢ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å¤–ã‚Œå€¤ã¨ã™ã‚‹ã€‚"""
    if len(notes) < 10:
        return notes
    arr = np.array(notes)
    ref = np.percentile(arr, percentile)
    threshold = ref * (2 ** (max_semitones_gap / 12))
    result = [f for f in notes if f <= threshold]
    removed = len(notes) - len(result)
    if removed > 0:
        print(f"[DEBUG] çµ±è¨ˆå¤–ã‚Œå€¤é™¤å»: {removed}ãƒ•ãƒ¬ãƒ¼ãƒ å‰Šé™¤ "
              f"(å‚ç…§P{percentile}={ref:.1f}Hz, é–¾å€¤={threshold:.1f}Hz)")
    return result if result else notes  # å…¨é™¤å»ã‚’é˜²æ­¢


# ============================================================
# _get_robust_max
# æœ€é«˜éŸ³å€™è£œã®æœ€å°æŒç¶šãƒ•ãƒ¬ãƒ¼ãƒ è¦ä»¶ï¼ˆä¸€ç¬ã®ãƒã‚¤ã‚ºã‚’é™¤å¤–ï¼‰
# ============================================================
def _get_robust_max(notes, min_sustain=None):
    """æœ€é«˜éŸ³å€™è£œãŒ min_sustain ãƒ•ãƒ¬ãƒ¼ãƒ ä»¥ä¸Šå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’è¦æ±‚ã€‚
    1åŠéŸ³ä»¥å†…ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã§ã‚«ã‚¦ãƒ³ãƒˆã€‚ä¸è¶³ãªã‚‰æ®µéšçš„ã«ä¸‹ã’ã‚‹ã€‚"""
    if min_sustain is None:
        min_sustain = MIN_SUSTAIN_FRAMES
    if not notes:
        return None
    arr = sorted(notes, reverse=True)
    semitone = 2 ** (1 / 12)
    checked = set()
    for candidate in arr:
        key = round(candidate, 1)
        if key in checked:
            continue
        checked.add(key)
        count = sum(1 for f in notes if candidate / semitone <= f <= candidate * semitone)
        if count >= min_sustain:
            return candidate
    return arr[0]  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…¨ã¦ä¸è¶³ãªã‚‰å…ƒã®max


# ============================================================
# check_octave_by_spectrum
# CREPEãŒviterbiå¹³æ»‘åŒ–ã§1ã‚ªã‚¯ã‚¿ãƒ¼ãƒ–ä½ãæ¤œå‡ºã—ãŸå ´åˆã®è£œæ­£
# ============================================================
def check_octave_by_spectrum(y_seg: np.ndarray, sr: int, candidate_hz: float) -> float:
    doubled = candidate_hz * 2
    if doubled > sr / 2 * 0.9 or doubled > VOICE_MAX_HZ or len(y_seg) < 512:
        return candidate_hz

    n_fft = 8192
    win   = np.hanning(min(len(y_seg), n_fft))
    y_w   = np.zeros(n_fft)
    n     = min(len(y_seg), n_fft)
    y_w[:n] = y_seg[:n] * win[:n]
    fft   = np.abs(np.fft.rfft(y_w))
    freqs = np.fft.rfftfreq(n_fft, 1.0 / sr)

    def band_energy(hz, width=0.04):
        if hz <= 0 or hz >= sr / 2:
            return 0.0
        lo = np.searchsorted(freqs, hz * (1 - width))
        hi = np.searchsorted(freqs, hz * (1 + width))
        return float(np.max(fft[lo:hi])) if lo < hi else 0.0

    e_candidate = band_energy(candidate_hz)
    e_doubled   = band_energy(doubled)

    if e_candidate <= 1e-10:
        return candidate_hz

    ratio = e_doubled / e_candidate
    # doubled ãŒ candidate ã‚ˆã‚Šæ˜ç¢ºã«å¼·ã„å ´åˆã®ã¿è£œæ­£ï¼ˆé–¾å€¤1.2ï¼‰
    if ratio >= 1.2:
        print(f"[DEBUG] æœ€é«˜éŸ³ã‚ªã‚¯ã‚¿ãƒ¼ãƒ–ä¿®æ­£: {candidate_hz:.1f}â†’{doubled:.1f}Hz ratio={ratio:.2f}")
        return doubled
    return candidate_hz


# ============================================================
# get_min_max_from_crepe
# ============================================================
def get_min_max_from_crepe(f0: np.ndarray, conf: np.ndarray,
                            y_16k: np.ndarray = None,
                            sr_crepe: int = 16000,
                            hop_length: int = 80,
                            valid_indices: np.ndarray = None) -> tuple:
    """
    CREPEã®confidenceã‚’ä½¿ã£ã¦min/maxã‚’å–å¾—ã€‚

    valid_indices: f0ãŒf0_np[valid_indices]ã§ä½œã‚‰ã‚ŒãŸå ´åˆã«ã€
                   y_16kä¸Šã®æ­£ã—ã„ä½ç½®ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã«å¿…è¦ã€‚
                   Noneã®å ´åˆã¯f0å†…ã®ãƒ­ãƒ¼ã‚«ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨ï¼ˆä¸æ­£ç¢ºï¼‰ã€‚
    """
    if len(f0) == 0:
        return 0.0, 0.0

    # ---- æœ€é«˜éŸ³: conf >= 0.3 ã®æœ€å¤§å€¤ ----
    for max_th in [0.3, 0.15, 0.05]:
        mask_max = conf >= max_th
        if mask_max.sum() >= 1:
            break
    raw_max = float(np.max(f0[mask_max]))

    # ã‚¹ãƒšã‚¯ãƒˆãƒ«ã§ã‚ªã‚¯ã‚¿ãƒ¼ãƒ–è£œæ­£
    if y_16k is not None:
        local_indices_max = np.where(mask_max)[0]
        local_max_idx     = local_indices_max[np.argmax(f0[local_indices_max])]
        if valid_indices is not None:
            orig_frame_idx = int(valid_indices[local_max_idx])
        else:
            orig_frame_idx = int(local_max_idx)
        center    = orig_frame_idx * hop_length
        seg       = y_16k[max(0, center - 4096): min(len(y_16k), center + 4096)]
        raw_max   = check_octave_by_spectrum(seg, sr_crepe, raw_max)

    # ---- æœ€ä½éŸ³: conf >= 0.5 ã®æœ€å°å€¤ ----
    for min_th in [0.5, 0.35, 0.2, 0.1]:
        mask_min = conf >= min_th
        if mask_min.sum() >= 3:
            break
    overall_min = float(np.min(f0[mask_min]))

    print(f"[DEBUG] max_th={max_th:.2f} min_th={min_th:.2f} "
          f"max_frames={mask_max.sum()} min_frames={mask_min.sum()} "
          f"raw_min={overall_min:.1f} raw_max={raw_max:.1f}")
    return overall_min, raw_max


# ============================================================
# run_crepe
# ============================================================
def run_crepe(audio_tensor, sr, hop_length, device, model_size='tiny'):
    common = dict(
        audio=audio_tensor, sample_rate=sr, hop_length=hop_length,
        fmin=65, fmax=1400, model=model_size,
        batch_size=2048, device=device, return_periodicity=True,
    )
    # é«˜é€ŸåŒ–: weighted_argmaxå„ªå…ˆï¼ˆviterbiã‚ˆã‚Š2-3å€é«˜é€Ÿï¼‰
    for name, get_dec in [
        ("weighted_argmax", lambda: torchcrepe.decode.weighted_argmax),
        ("viterbi",         lambda: torchcrepe.decode.viterbi),
        ("none",            None),
    ]:
        try:
            print(f"[DEBUG] ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ '{name}' ã§è©¦è¡Œä¸­...")
            kw = {**common, "decoder": get_dec()} if get_dec else common
            f0, conf = torchcrepe.predict(**kw)
            print(f"[INFO] âœ… CREPE ({model_size}, {name}) æˆåŠŸ")
            return f0, conf
        except (AttributeError, TypeError) as e:
            print(f"[WARN] âš ï¸ decoder={name} å¤±æ•—: {e}")
        except Exception:
            raise
    raise RuntimeError("torchcrepe: å…¨ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã§å¤±æ•—")


# ============================================================
# analyze â€” ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–¢æ•°ç¾¤
# ============================================================

def _load_audio(wav_path: str) -> dict:
    """WAVèª­è¾¼+ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ â†’ dict(y, sr) or dict(error)"""
    print(f"\n{'='*60}")
    print(f"[INFO] ğŸµ åˆ†æé–‹å§‹: {wav_path}")
    print(f"{'='*60}")

    print(f"[STEP 1/7] ğŸ“ WAVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
    try:
        y, sr = sf.read(wav_path)
        if len(y.shape) > 1:
            print(f"[INFO] ã‚¹ãƒ†ãƒ¬ã‚ªã‚’ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›ä¸­...")
            y = np.mean(y, axis=1)
        y = y.astype(np.float32)
    except Exception as e:
        return {"error": f"WAVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"}

    duration = len(y) / sr
    print(f"[DEBUG] âœ… èª­è¾¼å®Œäº†: SR={sr}, duration={duration:.2f}s, max={np.max(np.abs(y)):.4f}")

    if duration < 0.3:
        return {"error": "éŸ³å£°ãŒçŸ­ã™ãã¾ã™ï¼ˆ0.3ç§’ä»¥ä¸Šå¿…è¦ï¼‰ã€‚"}
    if np.max(np.abs(y)) < 0.0001:
        return {"error": "éŸ³ãŒå°ã•ã™ãã¾ã™ï¼ˆã»ã¼ç„¡éŸ³ï¼‰ã€‚"}

    return {"y": y, "sr": sr}


def _preprocess(y: np.ndarray, sr: int) -> dict:
    """æ­£è¦åŒ–+ãƒªã‚µãƒ³ãƒ—ãƒ«+ãƒ†ãƒ³ã‚½ãƒ« â†’ dict(y_16k, sr_crepe, hop_length, device, audio_tensor)"""
    print(f"\n[STEP 2/7] ğŸ”§ éŸ³å£°å‰å‡¦ç†ä¸­...")
    print(f"[INFO] éŸ³é‡æ­£è¦åŒ–ä¸­... (ç›®æ¨™: 0.95)")
    y = y / (np.max(np.abs(y)) + 1e-8) * 0.95

    sr_crepe   = CREPE_SR
    print(f"[INFO] ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ä¸­: {sr}Hz â†’ {sr_crepe}Hz")
    y_16k      = librosa.resample(y, orig_sr=sr, target_sr=sr_crepe) if sr != sr_crepe else y.copy()
    hop_length = CREPE_HOP_LENGTH
    device     = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"[INFO] ãƒ‡ãƒã‚¤ã‚¹: {device.upper()} (hop_length={hop_length})")
    audio_tensor = torch.tensor(np.copy(y_16k)).unsqueeze(0)
    print(f"[DEBUG] âœ… å‰å‡¦ç†å®Œäº†: tensor shape={audio_tensor.shape}")

    return {
        "y_16k": y_16k, "sr_crepe": sr_crepe,
        "hop_length": hop_length, "device": device,
        "audio_tensor": audio_tensor,
    }


def _run_pitch_detection(audio_tensor, sr: int, hop_length: int, device: str) -> dict:
    """CREPEå®Ÿè¡Œ â†’ dict(f0, conf) or dict(error)"""
    print(f"\n[STEP 3/7] ğŸ¼ CREPEéŸ³é«˜æ¨å®šä¸­...")
    f0_raw = conf_raw = None
    for model_size in ['tiny', 'small']:
        try:
            print(f"[INFO] CREPEãƒ¢ãƒ‡ãƒ« '{model_size}' ã§è©¦è¡Œä¸­... (device={device})")
            f0_raw, conf_raw = run_crepe(audio_tensor, sr, hop_length, device, model_size)
            print(f"[DEBUG] âœ… CREPE ({model_size}) æˆåŠŸ")
            break
        except Exception as e:
            print(f"[ERROR] âŒ CREPE ({model_size}) å¤±æ•—: {type(e).__name__}: {e}")

    if f0_raw is None:
        return {"error": "è§£æã‚¨ãƒ³ã‚¸ãƒ³(CREPE)ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸã€‚"}

    f0_np   = f0_raw.squeeze().detach().cpu().numpy()
    conf_np = conf_raw.squeeze().detach().cpu().numpy()
    print(f"[DEBUG] CREPEå®Œäº†: frames={len(f0_np)} conf_max={np.max(conf_np):.4f} conf_mean={np.mean(conf_np):.4f}")

    return {"f0": f0_np, "conf": conf_np}


def _filter_frames(f0_np: np.ndarray, conf_np: np.ndarray) -> dict:
    """ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°+ã‚ªã‚¯ã‚¿ãƒ¼ãƒ–è£œæ­£+ä¸­å¤®å€¤ â†’ dict or dict(error)"""
    print(f"\n[STEP 4/7] ğŸ¯ ä¿¡é ¼åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ä¸­...")

    # --- confidence ãƒ•ã‚£ãƒ«ã‚¿ ---
    for th in CONF_THRESHOLDS:
        idx = np.where(conf_np >= th)[0]
        if len(idx) >= CONF_MIN_FRAMES:
            valid_indices = idx
            print(f"[INFO] âœ… æœ‰åŠ¹ãƒ•ãƒ¬ãƒ¼ãƒ æ¤œå‡º: {len(idx)}å€‹ (confidence threshold={th:.2f})")
            break
    else:
        return {"error": f"æ­Œå£°ãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚(conf_max={np.max(conf_np):.4f})"}

    f0_v   = f0_np[valid_indices].copy()
    conf_v = conf_np[valid_indices].copy()

    print(f"[INFO] äººå£°éŸ³åŸŸãƒ•ã‚£ãƒ«ã‚¿é©ç”¨ä¸­ ({VOICE_MIN_HZ}Hz - {VOICE_MAX_HZ}Hz)...")
    # --- äººå£°çµ¶å¯¾ç¯„å›² ---
    mask   = (f0_v >= VOICE_MIN_HZ) & (f0_v <= VOICE_MAX_HZ)
    f0_v   = f0_v[mask]
    conf_v = conf_v[mask]
    valid_indices_filtered = valid_indices[mask]
    print(f"[DEBUG] âœ… äººå£°ç¯„å›²å†…: {len(f0_v)}ãƒ•ãƒ¬ãƒ¼ãƒ ")

    if len(f0_v) == 0:
        return {"error": "äººå£°ã®éŸ³åŸŸç¯„å›²å†…ã®éŸ³ãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"}

    print(f"\n[STEP 5/7] ğŸ“Š éŸ³åŸŸãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­...")
    # --- ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ¼åˆ¤å®šç”¨ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆmin/maxã¨ã¯ç‹¬ç«‹ï¼‰ ---
    print(f"[INFO] ç•°å¸¸å€¤é™¤å»ä¸­ (ä¸‹{UNREALISTIC_LOWER_OCT}oct / ä¸Š{UNREALISTIC_UPPER_OCT}oct)...")
    f0_reg, conf_reg = remove_unrealistic_range(f0_v, conf_v)
    if len(f0_reg) == 0:
        return {"error": "æœ‰åŠ¹ãªéŸ³åŸŸãƒ‡ãƒ¼ã‚¿ãŒæ®‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"}
    print(f"[DEBUG] âœ… æ®‹ç•™ãƒ•ãƒ¬ãƒ¼ãƒ : {len(f0_reg)}å€‹")

    # remove_unrealistic_rangeå¾Œã‚‚valid_indicesã‚’å¯¾å¿œã•ã›ã‚‹
    # â˜… åŒã˜å®šæ•°ã‚’ä½¿ã£ã¦å†å°å‡ºï¼ˆæ—§ã‚³ãƒ¼ãƒ‰ã® 2.0 vs 1.75 ä¸ä¸€è‡´ã‚’ä¿®æ­£ï¼‰
    lower_factor = 2 ** UNREALISTIC_LOWER_OCT
    upper_factor = 2 ** UNREALISTIC_UPPER_OCT
    hc      = conf_v >= 0.3
    median0 = np.median(f0_v[hc]) if hc.sum() >= 3 else np.median(f0_v)
    reg_mask = (f0_v >= median0 / lower_factor) & (f0_v <= median0 * upper_factor)
    valid_indices_reg = valid_indices_filtered[reg_mask]

    print(f"[INFO] ã‚ªã‚¯ã‚¿ãƒ¼ãƒ–ã‚¨ãƒ©ãƒ¼ä¿®æ­£ä¸­...")
    f0_reg_fixed = fix_octave_errors(f0_reg, conf_reg)

    # ä¿¡é ¼åº¦é‡ã¿ä»˜ãä¸­å¤®å€¤
    print(f"[INFO] ä¸­å¤®å€¤è¨ˆç®—ä¸­...")
    sort_idx    = np.argsort(f0_reg_fixed)
    cum_conf    = np.cumsum(conf_reg[sort_idx])
    mid_idx     = np.searchsorted(cum_conf, cum_conf[-1] / 2)
    median_freq = f0_reg_fixed[sort_idx[mid_idx]]
    print(f"[DEBUG] âœ… ä¸­å¤®å€¤={median_freq:.1f} Hz, ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ¼åˆ¤å®šãƒ•ãƒ¬ãƒ¼ãƒ æ•°={len(f0_reg_fixed)}")

    return {
        "f0_reg": f0_reg, "f0_reg_fixed": f0_reg_fixed,
        "conf_reg": conf_reg, "valid_indices_reg": valid_indices_reg,
        "median_freq": median_freq,
    }


def _classify_frames(filtered: dict, y_16k: np.ndarray, sr_crepe: int,
                     hop_length: int, no_falsetto: bool,
                     already_separated: bool) -> tuple:
    """ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ¼åˆ¤å®š â†’ (chest_notes, falsetto_notes)"""
    f0_reg_fixed     = filtered["f0_reg_fixed"]
    f0_reg           = filtered["f0_reg"]
    conf_reg         = filtered["conf_reg"]
    valid_indices_reg = filtered["valid_indices_reg"]
    median_freq      = filtered["median_freq"]

    print(f"\n[STEP 6/7] ğŸ¤ ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ¼åˆ¤å®šä¸­...")

    if no_falsetto:
        # === no_falsetto ãƒ¢ãƒ¼ãƒ‰: å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åœ°å£°ã¨ã—ã¦æ‰±ã† ===
        print(f"[INFO] no_falsetto=True: è£å£°åˆ¤å®šã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã€å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åœ°å£°ã¨ã—ã¦å‡¦ç†")
        chest_notes = [f for f in f0_reg_fixed if VOICE_MIN_HZ <= f <= VOICE_MAX_HZ]
        falsetto_notes = []
        # no_falsettoã§ã¯ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ¼åˆ¤å®šãŒãªã„ãŸã‚ã€ä¼´å¥æ··å…¥ã‚„CREPEã‚ªã‚¯ã‚¿ãƒ¼ãƒ–ã‚¨ãƒ©ãƒ¼ãŒ
        # å…¨ã¦åœ°å£°ã«å«ã¾ã‚ŒP97ãŒæ±šæŸ“ã•ã‚Œã‚‹ã€‚P95ã‚’ä½¿ã„ã€ä¸»æ­Œå£°åˆ†å¸ƒã®ä¸Šç«¯ã‚’åŸºæº–ã«ã™ã‚‹ã€‚
        chest_notes = remove_statistical_outliers(
            chest_notes,
            percentile=NO_FALSETTO_OUTLIER_PERCENTILE,
            max_semitones_gap=NO_FALSETTO_OUTLIER_GAP_ST,
        )
        chest_notes = remove_isolated_extremes(chest_notes)
        return chest_notes, falsetto_notes

    # === é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ¼åˆ¤å®š ===
    chest_notes    = []
    falsetto_notes = []
    frame_len      = 2048
    total_frames   = len(f0_reg_fixed)
    progress_interval = max(1, total_frames // 10)

    reset_register_stats()  # çµ±è¨ˆæƒ…å ±ã‚’ãƒªã‚»ãƒƒãƒˆ
    graduated_conf_filtered = 0
    print(f"[INFO] {total_frames}ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†ä¸­...")
    for i in range(total_frames):
        if i % progress_interval == 0 and i > 0:
            progress = (i / total_frames) * 100
            print(f"[INFO] é€²æ—: {progress:.0f}% ({i}/{total_frames}) - åœ°å£°:{len(chest_notes)} è£å£°:{len(falsetto_notes)}")
        freq = f0_reg_fixed[i]
        if not (VOICE_MIN_HZ <= freq <= VOICE_MAX_HZ):
            continue
        # --- æ®µéšçš„ä¿¡é ¼åº¦è¦æ±‚: ä¸­å¤®å€¤ã‹ã‚‰é ã„ã»ã©é«˜ã„ä¿¡é ¼åº¦ã‚’è¦æ±‚ ---
        orig_freq = f0_reg[i]
        if orig_freq > median_freq:
            octaves_above = np.log2(orig_freq / median_freq)
            if octaves_above > 1.5:
                min_conf = GRADUATED_CONF_FAR
            elif octaves_above > 1.0:
                min_conf = GRADUATED_CONF_MID
            else:
                min_conf = GRADUATED_CONF_NEAR
            if conf_reg[i] < min_conf:
                graduated_conf_filtered += 1
                continue
        frame_idx = valid_indices_reg[i]
        center    = int(frame_idx) * hop_length
        start     = max(0, center - frame_len // 2)
        end       = min(len(y_16k), center + frame_len // 2)
        frame     = y_16k[start:end]
        if len(frame) < 512:
            continue
        try:
            reg = classify_register(frame, sr_crepe, freq, median_freq, already_separated,
                                    crepe_conf=float(conf_reg[i]))
            if reg == "falsetto":
                falsetto_notes.append(freq)
            elif reg == "chest":
                chest_notes.append(freq)
            # reg == "unknown" ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆç„¡å£°éŸ³ãƒ»ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ï¼‰
        except Exception:
            continue

    print_register_summary()  # ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ¼åˆ¤å®šã®ã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›

    if graduated_conf_filtered > 0:
        print(f"[DEBUG] æ®µéšçš„ä¿¡é ¼åº¦ãƒ•ã‚£ãƒ«ã‚¿: {graduated_conf_filtered}ãƒ•ãƒ¬ãƒ¼ãƒ é™¤å¤–")

    # è£å£°è¡¨ç¤ºãƒ•ã‚£ãƒ«ã‚¿: 330Hzæœªæº€ã®ã€Œè£å£°ã€ã¯æ¯æ··ã˜ã‚Šåœ°å£°ã®å¯èƒ½æ€§ãŒé«˜ã„
    falsetto_orig  = list(falsetto_notes)
    falsetto_notes = [f for f in falsetto_orig if f >= FALSETTO_DISPLAY_MIN_HZ]
    low_falsetto   = [f for f in falsetto_orig if f < FALSETTO_DISPLAY_MIN_HZ]
    chest_notes.extend(low_falsetto)
    if low_falsetto:
        print(f"[DEBUG] {len(low_falsetto)}ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è£å£°â†’åœ°å£°ã«å†åˆ†é¡")

    if not chest_notes and not falsetto_notes:
        print(f"[WARN] ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ¼åˆ¤å®šçµæœãªã—ã€‚å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åœ°å£°ã¨ã—ã¦å‡¦ç†")
        chest_notes = f0_reg_fixed.tolist()

    # ãƒ‡ãƒãƒƒã‚°: æœ€é«˜éŸ³ä»˜è¿‘ï¼ˆä¸Šä½10Hzï¼‰ã®åˆ¤å®šçŠ¶æ³ã‚’ç¢ºèª
    if chest_notes or falsetto_notes:
        all_freqs = chest_notes + falsetto_notes
        if all_freqs:
            max_freq = max(all_freqs)
            high_threshold = max_freq - 10
            high_chest = [f for f in chest_notes if f >= high_threshold]
            high_falsetto = [f for f in falsetto_notes if f >= high_threshold]
            print(f"[DEBUG] æœ€é«˜éŸ³ä»˜è¿‘ï¼ˆ{high_threshold:.1f}Hzä»¥ä¸Šï¼‰: åœ°å£°{len(high_chest)}ãƒ•ãƒ¬ãƒ¼ãƒ , è£å£°{len(high_falsetto)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
            if high_chest and high_falsetto:
                print(f"[DEBUG] â†’ åœ°å£°æœ€é«˜: {max(high_chest):.1f}Hz, è£å£°æœ€é«˜: {max(high_falsetto):.1f}Hz")

    # === çµ±è¨ˆçš„å¤–ã‚Œå€¤é™¤å»ï¼ˆãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®å®‰å…¨ãƒãƒƒãƒˆï¼‰ ===
    chest_notes = remove_statistical_outliers(
        chest_notes,
        percentile=CHEST_OUTLIER_PERCENTILE,
        max_semitones_gap=CHEST_OUTLIER_GAP_ST,
    )
    falsetto_notes = remove_statistical_outliers(
        falsetto_notes,
        percentile=FALSETTO_OUTLIER_PERCENTILE,
        max_semitones_gap=FALSETTO_OUTLIER_GAP_ST,
    )

    # === å­¤ç«‹ã—ãŸæ¥µç«¯å€¤ã‚’é™¤å»ï¼ˆãƒã‚¤ã‚ºæœ€çµ‚é˜²è¡›ç·šï¼‰ ===
    chest_notes = remove_isolated_extremes(chest_notes)
    falsetto_notes = remove_isolated_extremes(falsetto_notes)

    # === æœ€é«˜éŸ³ä»˜è¿‘ã®æ··åœ¨åˆ¤å®šã‚’è§£æ¶ˆ ===
    if chest_notes and falsetto_notes:
        all_freqs = chest_notes + falsetto_notes
        max_freq = max(all_freqs)
        cleanup_factor = 2 ** (CLEANUP_SEMITONES / 12)
        high_range_threshold = max_freq / cleanup_factor

        high_chest_frames = [f for f in chest_notes if f >= high_range_threshold]
        high_falsetto_frames = [f for f in falsetto_notes if f >= high_range_threshold]

        # ä¸¡æ–¹å­˜åœ¨ã™ã‚‹å ´åˆã€æœ€é«˜éŸ³ä»˜è¿‘ã§ã¯è£å£°ã‚’å„ªå…ˆï¼ˆé«˜éŸ³ã¯è£å£°ã§å‡ºã™ã®ãŒè‡ªç„¶ï¼‰
        if high_chest_frames and high_falsetto_frames:
            chest_notes = [f for f in chest_notes if f < high_range_threshold]
            print(f"[INFO] æœ€é«˜éŸ³ä»˜è¿‘ã®åœ°å£°{len(high_chest_frames)}ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é™¤å¤–ï¼ˆè£å£°{len(high_falsetto_frames)}ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å„ªå…ˆæ¡ç”¨ï¼‰")

        # ãƒ©ãƒ™ãƒ«å¤‰æ›å¾Œã®å®‰å…¨ãƒã‚§ãƒƒã‚¯: é‡å­åŒ–ã§åŒã˜éŸ³åã«ãªã‚‹ã‚±ãƒ¼ã‚¹ã‚’é˜²æ­¢
        if chest_notes and falsetto_notes:
            f_label, _ = hz_to_label_and_hz(max(falsetto_notes))
            c_label, _ = hz_to_label_and_hz(max(chest_notes))
            if c_label == f_label:
                before_count = len(chest_notes)
                chest_notes = [f for f in chest_notes
                               if hz_to_label_and_hz(f)[0] != f_label]
                removed = before_count - len(chest_notes)
                print(f"[INFO] ãƒ©ãƒ™ãƒ«ä¸€è‡´'{c_label}'ã®åœ°å£°{removed}ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é™¤å¤–")

    return chest_notes, falsetto_notes


def _build_result(chest_notes: list, falsetto_notes: list,
                  f0_reg_fixed: np.ndarray, conf_reg: np.ndarray) -> dict:
    """çµæœdictæ§‹ç¯‰ â†’ result"""
    print(f"\n[STEP 7/7] ğŸ“‹ çµæœé›†è¨ˆä¸­...")

    all_notes   = chest_notes + falsetto_notes
    overall_min = float(np.min(all_notes))
    overall_max = float(np.max(all_notes))
    print(f"[DEBUG] å…¨ä½“éŸ³åŸŸ: min={overall_min:.1f}Hz max={overall_max:.1f}Hz")

    result = {}
    chest_avg_hz = float(np.mean(chest_notes)) if chest_notes else 0.0

    def add_range(notes, prefix):
        if not notes:
            return
        arr = np.array(notes)
        lo_label, lo_hz = hz_to_label_and_hz(float(np.min(arr)))
        robust_max = _get_robust_max(notes)
        hi_label, hi_hz = hz_to_label_and_hz(float(robust_max))
        raw_max = float(np.max(arr))
        if robust_max < raw_max:
            print(f"[INFO] {prefix} æœ€é«˜éŸ³å …ç‰¢åŒ–: {raw_max:.1f}Hz â†’ {robust_max:.1f}Hz (æŒç¶šä¸è¶³ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¹ã‚­ãƒƒãƒ—)")
        result[f"{prefix}_min"]    = lo_label
        result[f"{prefix}_max"]    = hi_label
        result[f"{prefix}_min_hz"] = lo_hz
        result[f"{prefix}_max_hz"] = hi_hz
        result[f"{prefix}_count"]  = len(arr)

    add_range(chest_notes,    "chest")
    add_range(falsetto_notes, "falsetto")

    # ãƒ‡ãƒãƒƒã‚°: åœ°å£°ã¨è£å£°ã®æœ€é«˜éŸ³Hzå€¤ã‚’å‡ºåŠ›
    if chest_notes and falsetto_notes:
        chest_max_hz = float(np.max(chest_notes))
        falsetto_max_hz = float(np.max(falsetto_notes))
        print(f"[DEBUG] åœ°å£°æœ€é«˜éŸ³: {chest_max_hz:.1f}Hz, è£å£°æœ€é«˜éŸ³: {falsetto_max_hz:.1f}Hz")
        if abs(chest_max_hz - falsetto_max_hz) < 5:
            print(f"[WARN] âš ï¸ åœ°å£°ã¨è£å£°ã®æœ€é«˜éŸ³ãŒè¿‘ã„ï¼ˆå·®: {abs(chest_max_hz - falsetto_max_hz):.1f}Hzï¼‰")

    ovr_min_label, ovr_min_hz = hz_to_label_and_hz(overall_min)
    ovr_max_label, ovr_max_hz = hz_to_label_and_hz(overall_max)
    result["overall_min"]    = ovr_min_label
    result["overall_max"]    = ovr_max_label
    result["overall_min_hz"] = ovr_min_hz
    result["overall_max_hz"] = ovr_max_hz

    total = len(chest_notes) + len(falsetto_notes)
    result["chest_ratio"]    = round(len(chest_notes)    / total * 100, 1) if total else 100.0
    result["falsetto_ratio"] = round(len(falsetto_notes) / total * 100, 1) if total else 0.0
    result["chest_avg_hz"]   = round(chest_avg_hz, 1)

    # === æ­Œå”±åŠ›åˆ†æ ===
    try:
        from recommender import analyze_singing_ability
        result["singing_analysis"] = analyze_singing_ability(
            f0_array=f0_reg_fixed,
            conf_array=conf_reg,
            chest_notes=chest_notes,
            falsetto_notes=falsetto_notes,
            overall_min_hz=overall_min,
            overall_max_hz=overall_max,
        )
    except Exception as e:
        print(f"[WARN] æ­Œå”±åŠ›åˆ†æã‚¹ã‚­ãƒƒãƒ—: {e}")

    print(f"\n{'='*60}")
    print(f"[INFO] âœ… è§£æå®Œäº†!")
    print(f"{'='*60}")
    print(f"ğŸ“Š æœ€çµ‚çµæœ:")
    print(f"  å…¨ä½“éŸ³åŸŸ: {result.get('overall_min', 'N/A')} - {result.get('overall_max', 'N/A')}")
    if 'chest_min' in result:
        print(f"  åœ°å£°éŸ³åŸŸ: {result.get('chest_min', 'N/A')} - {result.get('chest_max', 'N/A')} ({result.get('chest_ratio', 0)}%)")
    if 'falsetto_min' in result:
        print(f"  è£å£°éŸ³åŸŸ: {result.get('falsetto_min', 'N/A')} - {result.get('falsetto_max', 'N/A')} ({result.get('falsetto_ratio', 0)}%)")
    print(f"{'='*60}\n")
    return result


# ============================================================
# analyze â€” ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿
# ============================================================
def analyze(wav_path: str, already_separated: bool = False, no_falsetto: bool = False) -> dict:
    audio = _load_audio(wav_path)
    if "error" in audio:
        return audio

    prep = _preprocess(audio["y"], audio["sr"])

    pitch = _run_pitch_detection(prep["audio_tensor"], prep["sr_crepe"],
                                 prep["hop_length"], prep["device"])
    if "error" in pitch:
        return pitch

    filtered = _filter_frames(pitch["f0"], pitch["conf"])
    if "error" in filtered:
        return filtered

    chest, falsetto = _classify_frames(
        filtered, prep["y_16k"], prep["sr_crepe"],
        prep["hop_length"], no_falsetto, already_separated,
    )

    return _build_result(chest, falsetto, filtered["f0_reg_fixed"], filtered["conf_reg"])
